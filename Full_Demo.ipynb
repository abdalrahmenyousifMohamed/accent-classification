{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aaSzZF23oNR",
        "outputId": "4d10da5c-a722-41f6-b41b-2ec5f92e9489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: yt_dlp in /usr/local/lib/python3.11/dist-packages (2025.4.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets accelerate torchaudio moviepy speechbrain --quiet\n",
        "!apt install ffmpeg --quiet\n",
        "!pip install yt_dlp --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-IO60nAKZZe",
        "outputId": "8ea0bca7-a915-436f-e186-968ef3e18e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/audios/videoplayback.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    creation_time   : 2024-09-15T07:14:51.000000Z\n",
            "    encoder         : Google\n",
            "  Duration: 00:10:52.39, start: 0.000000, bitrate: 129 kb/s\n",
            "  Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 1 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-09-15T07:14:51.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to '/content/audios/videoplayback.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : dash\n",
            "    minor_version   : 0\n",
            "    compatible_brands: iso6mp41\n",
            "    TSSE            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-09-15T07:14:51.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "size=   12538kB time=00:10:52.38 bitrate= 157.4kbits/s speed=  60x    \n",
            "video:0kB audio:12537kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.002695%\n"
          ]
        }
      ],
      "source": [
        "# !ffmpeg -i /content/audios/videoplayback.mp4 -q:a 0 -map a /content/audios/videoplayback.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vcXp82R3Yra",
        "outputId": "fc1f9837-81cc-4c8b-8068-b48fc58de8bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/pipelines/automatic_speech_recognition.py:312: FutureWarning: `max_new_tokens` is deprecated and will be removed in version 4.49 of Transformers. To remove this warning, pass `max_new_tokens` as a key inside `generate_kwargs` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/BVgnIYSKUjY?si=Mcmvamf-jqI3vvh2\n",
            "[youtube] BVgnIYSKUjY: Downloading webpage\n",
            "[youtube] BVgnIYSKUjY: Downloading tv client config\n",
            "[youtube] BVgnIYSKUjY: Downloading tv player API JSON\n",
            "[youtube] BVgnIYSKUjY: Downloading ios player API JSON\n",
            "[youtube] BVgnIYSKUjY: Downloading m3u8 information\n",
            "[info] BVgnIYSKUjY: Downloading 1 format(s): 251\n",
            "[download] Destination: audio.webm\n",
            "[download] 100% of    5.89MiB in 00:00:00 at 12.22MiB/s  \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio.webm (pass -k to keep)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcript:  I will unite our country, not with words, but with action. I will work day in and day out to deliver for you. This government will have integrity, professionalism and accountability at every level. Trust is earned and I will earn yours. Good morning. I've just been to Buckingham Palace and accepted His Majesty the King's invitation to form a government in his name. It is only right to explain why I am standing here as your new Prime Minister. Right now, our country is facing a profound economic crisis. The aftermath of COVID still lingers. Putin's war in Ukraine has destabilized energy markets and supply chains the world over. I want to pay tribute to my predecessor, Liz Truss. She was not wrong to want to improve growth in this country. It is a noble aim. And I admired her restlessness to create change. But some mistakes were made. Not born of ill will or bad intentions. Quite the opposite, in fact. But mistakes nonetheless. And I have been elected, as leader of my party, and your Prime Minister, in part, to fix them. And that work begins immediately. I will place economic stability and confidence at the heart of this government's agenda. This will mean difficult decisions to come. But you saw me, during Covid, doing everything I could to protect people and businesses with schemes like furlough. There are always limits, more so now than ever, but I promise you this, I will bring that same compassion to the challenges we face today. The government I lead will not leave the next generation, your children and grandchildren, with a debt to settle that we were too weak to pay ourselves. I will unite our country, not with words, but with action. I will work day in and day out to deliver for you. This government will have integrity, professionalism and accountability at every level. Trust is earned and I will earn yours. I will always be grateful to Boris Johnson for his incredible achievements as Prime Minister and I treasure his warmth and generosity of spirit. And I know he would agree that the mandate my party earned in 2019 is not the sole property of any one individual. It is a mandate that belongs to and unites all of us. And the heart of that mandate is our manifesto. I will deliver on its promise a stronger NHS, better schools, safer streets, control of our borders, protecting our environment, supporting our armed forces, levelling up and building an economy that embraces the opportunities of Brexit where businesses invest, innovate and create jobs. I understand how difficult this moment is. After the billions of pounds it cost us to combat Covid, after all the dislocation that caused, in the midst of a terrible war that must be seen successfully to its conclusions, I fully appreciate how hard things are. And I understand too that I have work to do to restore trust after all that has happened. All I can say is that I am not daunted. I know the high office I have accepted, and I hope to live up to its demands. But when the opportunity to serve comes along, you cannot question the moment, only your willingness. So I stand here before you, ready to lead our country into the future, to put your needs above politics, to reach out and build a government that represents the very best traditions of my party. Together we can achieve incredible things. We will create a future worthy of the sacrifices so many have made and fill tomorrow and every day thereafter with hope. Thank you. ... Diolch yn fawr. Gracias. you you\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in pretrained_models/spkrec-ecapa-voxceleb.\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/embedding_model.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /content/pretrained_models/spkrec-ecapa-voxceleb/embedding_model.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/mean_var_norm_emb.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /content/pretrained_models/spkrec-ecapa-voxceleb/mean_var_norm_emb.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/classifier.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /content/pretrained_models/spkrec-ecapa-voxceleb/classifier.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/content/pretrained_models/spkrec-ecapa-voxceleb/label_encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /content/pretrained_models/spkrec-ecapa-voxceleb/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /content/pretrained_models/spkrec-ecapa-voxceleb/embedding_model.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /content/pretrained_models/spkrec-ecapa-voxceleb/mean_var_norm_emb.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /content/pretrained_models/spkrec-ecapa-voxceleb/classifier.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /content/pretrained_models/spkrec-ecapa-voxceleb/label_encoder.ckpt\n",
            "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /content/pretrained_models/spkrec-ecapa-voxceleb/label_encoder.ckpt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accent': 'British', 'confidence': '14.55%', 'summary': 'The speaker most closely matches a British accent with a confidence score of 14.55%.'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import yt_dlp,requests\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, pipeline\n",
        "from speechbrain.pretrained import SpeakerRecognition\n",
        "\n",
        "# Set up Whisper model (Hugging Face version)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "tokenizer = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    \"openai/whisper-large-v3\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    use_safetensors=True,\n",
        ").to(device)\n",
        "\n",
        "whisper_pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer.tokenizer,\n",
        "    feature_extractor=tokenizer.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    chunk_length_s=30,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    return_timestamps=False,\n",
        "    torch_dtype=torch.float16,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "# Download or use local file\n",
        "# def extract_audio_from_video(video_path, output_path=\"audio.wav\"):\n",
        "#     try:\n",
        "#         clip = VideoFileClip(video_path)\n",
        "#         clip.audio.write_audiofile(output_path)\n",
        "#         return output_path\n",
        "#     except Exception as e:\n",
        "#         return '/content/audios/videoplayback.mp3'\n",
        "def extract_audio_from_video(url):\n",
        "    \"\"\"Downloads video from URL and extracts audio to 'audio.wav'.\"\"\"\n",
        "    if \"youtube.com\" in url or \"youtu.be\" in url:\n",
        "        # Use yt-dlp to get audio\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'outtmpl': 'audio.%(ext)s'\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        return \"audio.wav\"\n",
        "    elif url.lower().endswith((\".mp4\", \".m4v\")):\n",
        "        # Download file and extract audio via ffmpeg\n",
        "        local_file = \"temp_video.mp4\"\n",
        "        r = requests.get(url)\n",
        "        with open(local_file, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "        # Extract audio (mono 16kHz) – requires ffmpeg\n",
        "        os.system(f\"ffmpeg -y -i {local_file} -vn -acodec pcm_s16le -ar 16000 -ac 1 audio.wav\")\n",
        "        return \"audio.wav\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported URL format or host.\")\n",
        "# Transcribe + Compare accent\n",
        "def detect_accent(audio_path):\n",
        "    result = whisper_pipe(audio_path)\n",
        "    print(\"Transcript:\", result['text'])\n",
        "\n",
        "    classifier = SpeakerRecognition.from_hparams(\n",
        "        source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "        savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        "    )\n",
        "\n",
        "    # Reference accent files (must be uploaded) uncomment the ones you want to use\n",
        "    accents = {\n",
        "    \"Afrikaans\": \"/content/audios/afrikaans1.mp3\",\n",
        "    \"Agni\": \"/content/audios/agni1.mp3\",\n",
        "    \"Armenian\": \"/content/audios/armenian1.mp3\",\n",
        "    # \"Bengali\": \"/content/audios/bengali11.mp3\",\n",
        "    # \"Bulgarian\": \"/content/audios/bulgarian1.mp3\",\n",
        "    # \"Czech\": \"/content/audios/czech1.mp3\",\n",
        "    # \"Dutch\": \"/content/audios/dutch1.mp3\",\n",
        "    # \"English\": \"/content/audios/english1.mp3\",\n",
        "    # \"Farsi\": \"/content/audios/farsi5.mp3\",\n",
        "    # \"French\": \"/content/audios/french10.mp3\",\n",
        "    # \"German\": \"/content/audios/german1.mp3\",\n",
        "    # \"Greek\": \"/content/audios/greek1.mp3\",\n",
        "    # \"Hindi\": \"/content/audios/hindi2.mp3\",\n",
        "    # \"Icelandic\": \"/content/audios/icelandic1.mp3\",\n",
        "    # \"Japanese\": \"/content/audios/japanese11.mp3\",\n",
        "    # \"Korean\": \"/content/audios/korean25.mp3\",\n",
        "    # \"Mandarin\": \"/content/audios/mandarin2.mp3\",\n",
        "    # \"Polish\": \"/content/audios/polish2.mp3\",\n",
        "    # \"Portuguese\": \"/content/audios/portuguese17.mp3\",\n",
        "    # \"Romanian\": \"/content/audios/romanian19.mp3\",\n",
        "    # \"Russian\": \"/content/audios/russian2.mp3\",\n",
        "    # \"Slovak\": \"/content/audios/slovak1.mp3\",\n",
        "    # \"Spanish\": \"/content/audios/spanish111.mp3\",\n",
        "    # \"Swedish\": \"/content/audios/swedish1.mp3\",\n",
        "    # \"Tswana\": \"/content/audios/tswana2.mp3\",\n",
        "    # \"Turkish\": \"/content/audios/turkish1.mp3\",\n",
        "    # \"Urdu\": \"/content/audios/urdu1.mp3\",\n",
        "    # \"Uyghur\": \"/content/audios/uyghur1.mp3\",\n",
        "    # \"Vietnamese\": \"/content/audios/vietnamese1.mp3\",\n",
        "    # \"Yoruba\": \"/content/audios/yoruba1.mp3\",\n",
        "    \"British\" : \"/content/audios/5_min_british_sound.mp3\"\n",
        "}\n",
        "\n",
        "\n",
        "    scores = {}\n",
        "    for accent, ref_file in accents.items():\n",
        "        if not os.path.exists(ref_file):\n",
        "            print(f\"Missing reference file: {ref_file}\")\n",
        "            continue\n",
        "        score, _ = classifier.verify_files(ref_file, audio_path)\n",
        "        scores[accent] = float(score)\n",
        "\n",
        "    if not scores:\n",
        "        return {\"error\": \"No reference files found.\"}\n",
        "\n",
        "    best_accent = max(scores, key=scores.get)\n",
        "    confidence = round(scores[best_accent] * 100, 2)\n",
        "    return {\n",
        "        \"accent\": best_accent,\n",
        "        \"confidence\": f\"{confidence}%\",\n",
        "        \"summary\": f\"The speaker most closely matches a {best_accent} accent with a confidence score of {confidence}%.\"\n",
        "    }\n",
        "\n",
        "# Main logic\n",
        "def analyze_accent_from_video(video_path):\n",
        "    audio_path = extract_audio_from_video(video_path)\n",
        "    result = detect_accent(audio_path)\n",
        "    os.remove(audio_path)\n",
        "    return result\n",
        "\n",
        "video =\"https://youtu.be/BVgnIYSKUjY?si=Mcmvamf-jqI3vvh2\" # \"https://youtu.be/1i9kcBHX2Nw?si=AR6b7mGwul8mNWNa\"  # Upload your own short 5–20 sec .mp4 file\n",
        "result = analyze_accent_from_video(video)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEcBO4YWEfbY",
        "outputId": "3841ba6f-31a5-4d76-b3e5-4fdd675b82e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter video URL: https://youtu.be/BVgnIYSKUjY?si=Mcmvamf-jqI3vvh2\n",
            "Downloading and extracting audio...\n",
            "[youtube] Extracting URL: https://youtu.be/BVgnIYSKUjY?si=Mcmvamf-jqI3vvh2\n",
            "[youtube] BVgnIYSKUjY: Downloading webpage\n",
            "[youtube] BVgnIYSKUjY: Downloading tv client config\n",
            "[youtube] BVgnIYSKUjY: Downloading tv player API JSON\n",
            "[youtube] BVgnIYSKUjY: Downloading ios player API JSON\n",
            "[youtube] BVgnIYSKUjY: Downloading m3u8 information\n",
            "[info] BVgnIYSKUjY: Downloading 1 format(s): 251\n",
            "[download] Destination: audio.webm\n",
            "[download] 100% of    5.89MiB in 00:00:00 at 14.07MiB/s  \n",
            "[ExtractAudio] Destination: audio.wav\n",
            "Deleting original file audio.webm (pass -k to keep)\n",
            "Transcribing audio...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/pipelines/automatic_speech_recognition.py:312: FutureWarning: `max_new_tokens` is deprecated and will be removed in version 4.49 of Transformers. To remove this warning, pass `max_new_tokens` as a key inside `generate_kwargs` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/content/pretrained_models/accent-id-commonaccent_ecapa/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'Jzuluaga/accent-id-commonaccent_ecapa' if not cached\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription:  I will unite our country, not with words, but with action. I will work day in and day out to delive ...\n",
            "Classifying accent...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in pretrained_models/accent-id-commonaccent_ecapa.\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/pretrained_models/accent-id-commonaccent_ecapa/embedding_model.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /content/pretrained_models/accent-id-commonaccent_ecapa/embedding_model.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/content/pretrained_models/accent-id-commonaccent_ecapa/classifier.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /content/pretrained_models/accent-id-commonaccent_ecapa/classifier.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch accent_encoder.txt: Using symlink found at '/content/pretrained_models/accent-id-commonaccent_ecapa/label_encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /content/pretrained_models/accent-id-commonaccent_ecapa/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, classifier, label_encoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /content/pretrained_models/accent-id-commonaccent_ecapa/embedding_model.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /content/pretrained_models/accent-id-commonaccent_ecapa/classifier.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /content/pretrained_models/accent-id-commonaccent_ecapa/label_encoder.ckpt\n",
            "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /content/pretrained_models/accent-id-commonaccent_ecapa/label_encoder.ckpt\n",
            "WARNING:speechbrain.dataio.encoder:CategoricalEncoder.expect_len was never called: assuming category count of 16 to be correct! Sanity check your encoder using `.expect_len`. Ensure that downstream code also uses the correct size. If you are sure this does not apply to you, use `.ignore_len`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accent: ['england'] (72.0%)\n",
            "Explanation: Accent classification is uncertain; model confidence is moderate.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "import requests,torch\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, pipeline\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "def download_audio(url):\n",
        "    \"\"\"Downloads video from URL and extracts audio to 'audio.wav'.\"\"\"\n",
        "    if \"youtube.com\" in url or \"youtu.be\" in url:\n",
        "        # Use yt-dlp to get audio\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'outtmpl': 'audio.%(ext)s'\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        return \"audio.wav\"\n",
        "    elif url.lower().endswith((\".mp4\", \".m4v\")):\n",
        "        # Download file and extract audio via ffmpeg\n",
        "        local_file = \"temp_video.mp4\"\n",
        "        r = requests.get(url)\n",
        "        with open(local_file, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "        # Extract audio (mono 16kHz) – requires ffmpeg\n",
        "        os.system(f\"ffmpeg -y -i {local_file} -vn -acodec pcm_s16le -ar 16000 -ac 1 audio.wav\")\n",
        "        return \"audio.wav\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported URL format or host.\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"Transcribes the given audio file using Whisper.\"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    BATCH_SIZE = 8\n",
        "\n",
        "    tokenizer = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
        "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "        \"openai/whisper-large-v3\",\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True,\n",
        "        use_safetensors=True,\n",
        "    ).to(device)\n",
        "\n",
        "    whisper_pipe = pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer.tokenizer,\n",
        "        feature_extractor=tokenizer.feature_extractor,\n",
        "        max_new_tokens=128,\n",
        "        chunk_length_s=30,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        return_timestamps=False,\n",
        "        torch_dtype=torch.float16,\n",
        "        device=device,\n",
        "    )\n",
        "    result = whisper_pipe(audio_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def classify_accent(audio_path):\n",
        "    \"\"\"Classifies accent from audio using a pre-trained SpeechBrain model.\"\"\"\n",
        "    # Load the pretrained accent model (only needs to be done once ideally)\n",
        "    classifier = EncoderClassifier.from_hparams(\n",
        "        source=\"Jzuluaga/accent-id-commonaccent_ecapa\",\n",
        "        savedir=\"pretrained_models/accent-id-commonaccent_ecapa\"\n",
        "    )\n",
        "    out_prob, score, index, text_lab = classifier.classify_file(audio_path)\n",
        "    accent = text_lab  # label string, e.g. 'us', 'england', etc.\n",
        "    # confidence = float(np.max(out_prob) * 100) # This line is causing the error\n",
        "    confidence = float(torch.max(out_prob).item() * 100)  # Use torch.max() instead\n",
        "    return accent, confidence\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    video_url = input(\"Enter video URL: \").strip()\n",
        "    print(\"Downloading and extracting audio...\")\n",
        "    audio_file = download_audio(video_url)\n",
        "    print(\"Transcribing audio...\")\n",
        "    transcript = transcribe_audio(audio_file)\n",
        "    print(\"Transcription:\", transcript[:100], \"...\")\n",
        "    print(\"Classifying accent...\")\n",
        "    accent, conf = classify_accent(audio_file)\n",
        "    print(f\"Accent: {accent} ({conf:.1f}%)\")\n",
        "    print(\"Explanation: \", end=\"\")\n",
        "    if conf > 80:\n",
        "        print(\"Strong acoustic cues match typical \" + accent + \" English speech.\")\n",
        "    else:\n",
        "        print(\"Accent classification is uncertain; model confidence is moderate.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pDZ9za-G2-D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
